{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A First Encounter with Machine Learning\n",
    "\n",
    "Machine Learning (ML for short) is the art of building up and tuning computational algorithms having datasets as entry and mostly concerned about one of the two following tasks:\n",
    "\n",
    "* Looking into patterns shared by common subsets of individuals.\n",
    "* Predicting a feature out of the other ones.\n",
    "\n",
    "*Clustering* and *PCA* (a dimesnion reduction strategy) fit into the first headline, while *linear regression* or *random forest* fit into the second. \n",
    "\n",
    "We'll be going through a couple of ML models in this lecture. Theses models involve a lot of mathematics if worked out in detail. Since this is only an introduction to ML we'll be satisfied with using available models in the `sklearn` library, only giving a broad idea of thoses we encounter.\n",
    "\n",
    "### Supervised and Unsupervised Learning\n",
    "\n",
    "Most ML algorithms fit in one of the following headlines: \n",
    "\n",
    "* **Supervised Learning: ** it happens when we're looking into predicting a feature out of a number of others. For instance one could try predicting votes of a person out of their address, weight and salary assuming you have a dataset containing all such data including votes. One might also want to guess diameter of oranges depending on the number of sunny days per year, number of windy days including wind direction, average quantity of water used to water the trees. This would mean one has a diary of average orange diameters per year and all other pointed out data. \n",
    "\n",
    "* **Unsupervised Learning:** it does happen when you're looking into the inner strucutre of data. What features do people having a specific cancer have in common? What families of writing styles can one find in the late ninties novels? All such questions do not need pre-established and accessible answers. \n",
    "\n",
    "### Classification and Regression\n",
    "\n",
    "In *supervised learning* we've seen into types of different expectations : a *class* or a *float*. In the first case we're interested in classifying individuals. For instance an individual having a gun migh be labelled as a dangerous person ; he is classified in the *dangerous* category. The second case involves having output a *float* for each given entry. This is the case of predicting life expectency out of a number of known features.\n",
    "\n",
    "\n",
    "### Clustering and Dimensionality Reduction\n",
    "\n",
    "In *unsupervised learning* we're either trying to lower the number of parameters involved in the model or trying to group up individuals following a pre-established sense of similarity.\n",
    "\n",
    "\n",
    "### The `scikit-learn` Library\n",
    "\n",
    "It is the machine learning API available and most widely used in `python`. It's mean features are summed up in the short and nicely written article [here](https://arxiv.org/pdf/1309.0238.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sklearn` classes we'll be interested in are \n",
    "\n",
    "* estimators ; classes that train a chosen model and enable prediction on unseen data.\n",
    "* transformers ; there structure is built on the one of estimators though there use is different, they shall enable us to put data into proper shape to be fed for a chosen model. This is often called *preprocessing*.\n",
    "\n",
    "For a an overview of the `scikit-learn` library you're encouraged to have a look at the [official scikit-learn webpage](http://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Science Workflow\n",
    "\n",
    "Building up an ML model systematically runs through the following steps.\n",
    "\n",
    "* **Understand what you're looking for.**\n",
    "\n",
    "Until you're satisfied with the result :\n",
    "\n",
    "* **Choose a model that would the job :** start with the simplest get to more complex ones with each iteration.\n",
    "* **Train it on the data you have.**\n",
    "* **Evaluate the model prediction capacities :** depending on whether supervised or unsupervised learning you'll be doing different things here. In the case of supervised learning (which is the one we'll be mostly dealing with) you'll be testing your model prediction capacities on data entries it did not see while training. That the reason why you're going to isolate part of your data for testing as soon a you get the data in hand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than going through a more in-depth discussion about what ML is and how to do it we're going to go through an explicit example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten Digits Recognition\n",
    "\n",
    "Let's first fetch the data from available `sklearn` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original', data_home=\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *MNIST* dataset is one containing $70,000$ vectorized images of handwritten digits by high-schoolers and employees in the US. Aim is to decide on the number an image represents. \n",
    "\n",
    "`target` here is a vector of length $70,000$ corresponding the number same index image represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000,), (70000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.target.shape, mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of of features of dataset corresponds to the number of pixels in a $28\\times 28$ image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's extract entries and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have an idea of what the images look like we can plot them out of their serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(serial):\n",
    "    image = serial.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69ff7a59e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit_3 = X[20000]\n",
    "show_image(digit_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset Into Training and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a055cc0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you understand what has just happened? **Any idea as to why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Making Clear What We Are Going To Do\n",
    "\n",
    "We are going to train a *binary classifier* enabling us to check whether an image is a $3$ or not. Answer is thus a boolean and entry is still same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_3 = (y_train == 3)\n",
    "y_test_3 = (y_test == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_3[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Model\n",
    "\n",
    "Among the simplest models for classification is logistic regression. It's said to be a linear model. We shall try out this one first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression.fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a python class. It has to be instatiated first before training or using it for prediction. It belong to the class of estimators in `sklearn`. The ones we'll see will always share the methods :\n",
    "\n",
    "* **fit :** Fits the model to the data given checking using training dataset.\n",
    "* **predict :** Once trained the model can predict answer for new values (and might be wrong sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.fit(X_train, y_train_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_model.predict(digit_3.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see the example we've taken was well classified by the model. This not enough for evaluation though. The least we could ask for is that the proportion of errors on test set would be low enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_3 = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97371428571428575"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_3, y_predict_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score which looks rather high, before going further let's stop to look a minute for the proportion of $3$ in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.20142857142857"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y == 3).sum(0)/y.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of $3$s in the dataset is only $10\\%$. Which means a model only returning `False` has already $90\\%$ accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never3Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89928571428571424"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_3_clf = Never3Classifier()\n",
    "accuracy_score(y_test_3, never_3_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This enables us to put in perspective the high result we got for the `logistic regression` model. To get even further one can use `cross validation` in order to check accuracy of model on different portions of the dataset. \n",
    "\n",
    "One cuts training set into $k$ parts, trains iteratively on $k-1$ parts and tests it against the last $k$ part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97294836,  0.97417765,  0.97310618])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(log_model, X_train, y_train_3, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an important statistical issue under the cross validation strategy : you better choose a number of folds that is too small to have very different statistical features among them. Otherwise one will need to get hands a little dirty to do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A More Evolved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.fit(X_train, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_predict_3 = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97692857142857148"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(forest_predict_3, y_predict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97814442,  0.97680274,  0.97744562])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(forest_clf, X_train, y_train_3, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
